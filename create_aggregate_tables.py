"""
create_aggregate_tables.py - ëŒ€ì‹œë³´ë“œ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì§‘ê³„ í…Œì´ë¸” ìƒì„±
Version: 1.0.0
Created: 2024-01-24

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” schedule.dbì— ì‚¬ì „ ì§‘ê³„ í…Œì´ë¸”ì„ ìƒì„±í•˜ì—¬
ëŒ€ì‹œë³´ë“œ ë¡œë”© ì†ë„ë¥¼ 10ë°° ì´ìƒ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

"ê¸°íƒ€" ë°ì´í„°ëŠ” ì§‘ê³„ì—ì„œ ì œì™¸í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ë°ì´í„°ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sys

# ============================================================================
# ì„¤ì •
# ============================================================================

# ìƒë°©ì†¡ ì±„ë„ ì •ì˜
LIVE_CHANNELS = {
    'í˜„ëŒ€í™ˆì‡¼í•‘', 'GSí™ˆì‡¼í•‘', 'ë¡¯ë°í™ˆì‡¼í•‘', 'CJì˜¨ìŠ¤íƒ€ì¼', 
    'í™ˆì•¤ì‡¼í•‘', 'NSí™ˆì‡¼í•‘', 'ê³µì˜ì‡¼í•‘'
}

# ëª¨ë¸ë¹„ ì„¤ì •
MODEL_COST_LIVE = 10400000
MODEL_COST_NON_LIVE = 2000000

# ì „í™˜ìœ¨ ë° ë§ˆì§„ìœ¨ ì„¤ì • - ROI ê³„ì‚°ë²• ë³€ê²½ (2025-02-03)
CONVERSION_RATE = 0.75      # ì „í™˜ë¥  75%
PRODUCT_COST_RATE = 0.13    # ì œí’ˆ ì›ê°€ìœ¨ 13%
COMMISSION_RATE = 0.10      # íŒë§¤ ìˆ˜ìˆ˜ë£Œìœ¨ 10%
REAL_MARGIN_RATE = (1 - COMMISSION_RATE - PRODUCT_COST_RATE) * CONVERSION_RATE  # 0.5775 (57.75%)

# ============================================================================
# ì§‘ê³„ í…Œì´ë¸” ìƒì„± í´ë˜ìŠ¤
# ============================================================================

class AggregateTableCreator:
    def __init__(self, db_path="schedule.db"):
        """ì§‘ê³„ í…Œì´ë¸” ìƒì„±ê¸° ì´ˆê¸°í™”"""
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.cur = self.conn.cursor()
        
    def create_all_tables(self, exclude_others=True):
        """ëª¨ë“  ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("=" * 60)
        print("ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì‹œì‘")
        print("=" * 60)
        
        # ê¸°ì¡´ ì§‘ê³„ í…Œì´ë¸” ì‚­ì œ
        self._drop_existing_tables()
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = self._load_and_preprocess_data(exclude_others)
        
        if len(df) == 0:
            print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê° ì§‘ê³„ í…Œì´ë¸” ìƒì„±
        self._create_daily_aggregate(df)
        self._create_hourly_aggregate(df)
        self._create_platform_aggregate(df)
        self._create_category_aggregate(df)
        self._create_platform_hourly_aggregate(df)
        self._create_category_hourly_aggregate(df)
        self._create_weekday_aggregate(df)
        self._create_monthly_aggregate(df)
        
        # ì¸ë±ìŠ¤ ìƒì„±
        self._create_indexes()
        
        # í†µê³„ ì •ë³´ ì €ì¥
        self._save_statistics(df)
        
        print("\nâœ… ëª¨ë“  ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì™„ë£Œ!")
        self.conn.close()
    
    def _drop_existing_tables(self):
        """ê¸°ì¡´ ì§‘ê³„ í…Œì´ë¸” ì‚­ì œ"""
        print("\n[1/9] ê¸°ì¡´ ì§‘ê³„ í…Œì´ë¸” ì‚­ì œ ì¤‘...")
        
        tables = [
            'agg_daily', 'agg_hourly', 'agg_platform', 'agg_category',
            'agg_platform_hourly', 'agg_category_hourly', 'agg_weekday',
            'agg_monthly', 'agg_statistics'
        ]
        
        for table in tables:
            self.cur.execute(f"DROP TABLE IF EXISTS {table}")
        
        self.conn.commit()
        print("  âœ“ ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ ì™„ë£Œ")
    
    def _load_and_preprocess_data(self, exclude_others=True):
        """ì›ë³¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("\n[2/9] ì›ë³¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ê¸°íƒ€ ì œì™¸ ì˜µì…˜ì— ë”°ë¼ ì¿¼ë¦¬ ìˆ˜ì •
        if exclude_others:
            query = "SELECT * FROM schedule WHERE platform != 'ê¸°íƒ€'"
            print("  â„¹ï¸ 'ê¸°íƒ€' ë°ì´í„° ì œì™¸")
        else:
            query = "SELECT * FROM schedule"
        
        df = pd.read_sql_query(query, self.conn)
        print(f"  âœ“ {len(df):,}ê°œ ë ˆì½”ë“œ ë¡œë“œ")
        
        # ë‚ ì§œ ë³€í™˜
        df['date'] = pd.to_datetime(df['date'])
        
        # ì‹œê°„ ê´€ë ¨ ì»¬ëŸ¼ ìƒì„±
        df['hour'] = df['time'].str.split(':').str[0].astype(int)
        df['weekday'] = df['date'].dt.dayofweek
        df['month'] = df['date'].dt.to_period('M').astype(str)
        df['week'] = df['date'].dt.to_period('W').astype(str)
        df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)
        
        # ì±„ë„ êµ¬ë¶„
        df['is_live'] = df['platform'].isin(LIVE_CHANNELS).astype(int)
        df['model_cost'] = df['is_live'].apply(
            lambda x: MODEL_COST_LIVE if x else MODEL_COST_NON_LIVE
        )
        
        # ë¹„ìš© ê³„ì‚°
        df['total_cost'] = df['cost'] + df['model_cost']
        
        # ì‹¤ì§ˆ ìˆ˜ìµ ê³„ì‚° - ìƒˆë¡œìš´ ê³„ì‚°ë²• ì ìš©
        df['real_profit'] = (df['revenue'] * REAL_MARGIN_RATE) - df['total_cost']
        
        # ROI ê³„ì‚°
        df['roi_calculated'] = np.where(
            df['total_cost'] > 0,
            (df['real_profit'] / df['total_cost']) * 100,
            0
        )
        
        # íš¨ìœ¨ì„± ê³„ì‚°
        df['efficiency'] = np.where(
            df['total_cost'] > 0,
            df['revenue'] / df['total_cost'],
            0
        )
        
        print("  âœ“ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
        print(f"  â„¹ï¸ ì‹¤ì§ˆ ë§ˆì§„ìœ¨: {REAL_MARGIN_RATE:.2%} ì ìš©")
        return df
    
    def _create_daily_aggregate(self, df):
        """ì¼ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[3/9] ì¼ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        daily = df.groupby('date').agg({
            'revenue': ['sum', 'mean', 'std', 'min', 'max'],
            'units_sold': ['sum', 'mean'],
            'total_cost': 'sum',
            'real_profit': 'sum',
            'roi_calculated': 'mean',
            'efficiency': 'mean',
            'broadcast': 'count'
        }).reset_index()
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        daily.columns = [
            'date', 'revenue_sum', 'revenue_mean', 'revenue_std', 'revenue_min', 'revenue_max',
            'units_sum', 'units_mean', 'cost_sum', 'profit_sum', 
            'roi_mean', 'efficiency_mean', 'broadcast_count'
        ]
        
        # ì¶”ê°€ ì§€í‘œ
        daily['profit_rate'] = (daily['profit_sum'] / daily['revenue_sum'] * 100).fillna(0)
        daily['weekday'] = pd.to_datetime(daily['date']).dt.dayofweek
        daily['is_weekend'] = daily['weekday'].isin([5, 6]).astype(int)
        
        # DB ì €ì¥
        daily.to_sql('agg_daily', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(daily)}ê°œ ì¼ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_hourly_aggregate(self, df):
        """ì‹œê°„ëŒ€ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[4/9] ì‹œê°„ëŒ€ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        hourly = df.groupby('hour').agg({
            'revenue': ['sum', 'mean', 'std'],
            'units_sold': ['sum', 'mean'],
            'total_cost': 'sum',
            'real_profit': 'sum',
            'roi_calculated': 'mean',
            'efficiency': 'mean',
            'broadcast': 'count'
        }).reset_index()
        
        hourly.columns = [
            'hour', 'revenue_sum', 'revenue_mean', 'revenue_std',
            'units_sum', 'units_mean', 'cost_sum', 'profit_sum',
            'roi_mean', 'efficiency_mean', 'broadcast_count'
        ]
        
        # ì•ˆì •ì„± ì§€í‘œ (ë³€ë™ê³„ìˆ˜ì˜ ì—­ìˆ˜)
        hourly['stability'] = np.where(
            hourly['revenue_mean'] > 0,
            1 / (1 + hourly['revenue_std'] / hourly['revenue_mean']),
            0
        )
        
        hourly.to_sql('agg_hourly', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(hourly)}ê°œ ì‹œê°„ëŒ€ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_platform_aggregate(self, df):
        """ë°©ì†¡ì‚¬ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[5/9] ë°©ì†¡ì‚¬ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        platform = df.groupby('platform').agg({
            'revenue': ['sum', 'mean', 'std'],
            'units_sold': 'sum',
            'total_cost': 'sum',
            'real_profit': 'sum',
            'roi_calculated': 'mean',
            'efficiency': 'mean',
            'broadcast': 'count',
            'is_live': 'first'
        }).reset_index()
        
        platform.columns = [
            'platform', 'revenue_sum', 'revenue_mean', 'revenue_std',
            'units_sum', 'cost_sum', 'profit_sum', 'roi_mean',
            'efficiency_mean', 'broadcast_count', 'is_live'
        ]
        
        # ê°€ì¤‘í‰ê·  ROI ê³„ì‚°
        platform['roi_weighted'] = (platform['profit_sum'] / platform['cost_sum'] * 100).fillna(0)
        
        # ì±„ë„ íƒ€ì…
        platform['channel_type'] = platform['is_live'].apply(
            lambda x: 'ìƒë°©ì†¡' if x else 'ë¹„ìƒë°©ì†¡'
        )
        
        platform.to_sql('agg_platform', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(platform)}ê°œ ë°©ì†¡ì‚¬ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_category_aggregate(self, df):
        """ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[6/9] ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        category = df.groupby('category').agg({
            'revenue': ['sum', 'mean', 'std'],
            'units_sold': 'sum',
            'total_cost': 'sum',
            'real_profit': 'sum',
            'roi_calculated': 'mean',
            'broadcast': 'count'
        }).reset_index()
        
        category.columns = [
            'category', 'revenue_sum', 'revenue_mean', 'revenue_std',
            'units_sum', 'cost_sum', 'profit_sum', 'roi_mean', 'broadcast_count'
        ]
        
        # ì¸ê¸°ë„ ì ìˆ˜ (ë§¤ì¶œ + ë¹ˆë„ ê³ ë ¤)
        category['popularity_score'] = (
            category['revenue_sum'] / category['revenue_sum'].max() * 0.7 +
            category['broadcast_count'] / category['broadcast_count'].max() * 0.3
        ) * 100
        
        category.to_sql('agg_category', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(category)}ê°œ ì¹´í…Œê³ ë¦¬ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_platform_hourly_aggregate(self, df):
        """ë°©ì†¡ì‚¬-ì‹œê°„ëŒ€ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[7/9] ë°©ì†¡ì‚¬-ì‹œê°„ëŒ€ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        platform_hourly = df.groupby(['platform', 'hour']).agg({
            'revenue': ['sum', 'mean'],
            'roi_calculated': 'mean',
            'broadcast': 'count'
        }).reset_index()
        
        platform_hourly.columns = [
            'platform', 'hour', 'revenue_sum', 'revenue_mean',
            'roi_mean', 'broadcast_count'
        ]
        
        platform_hourly.to_sql('agg_platform_hourly', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(platform_hourly)}ê°œ ë°©ì†¡ì‚¬-ì‹œê°„ëŒ€ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_category_hourly_aggregate(self, df):
        """ì¹´í…Œê³ ë¦¬-ì‹œê°„ëŒ€ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[8/9] ì¹´í…Œê³ ë¦¬-ì‹œê°„ëŒ€ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        category_hourly = df.groupby(['category', 'hour']).agg({
            'revenue': ['sum', 'mean'],
            'roi_calculated': 'mean',
            'broadcast': 'count'
        }).reset_index()
        
        category_hourly.columns = [
            'category', 'hour', 'revenue_sum', 'revenue_mean',
            'roi_mean', 'broadcast_count'
        ]
        
        category_hourly.to_sql('agg_category_hourly', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(category_hourly)}ê°œ ì¹´í…Œê³ ë¦¬-ì‹œê°„ëŒ€ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_weekday_aggregate(self, df):
        """ìš”ì¼ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[9/9] ìš”ì¼ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        weekday = df.groupby('weekday').agg({
            'revenue': ['sum', 'mean'],
            'units_sold': 'sum',
            'roi_calculated': 'mean',
            'broadcast': 'count'
        }).reset_index()
        
        weekday.columns = [
            'weekday', 'revenue_sum', 'revenue_mean',
            'units_sum', 'roi_mean', 'broadcast_count'
        ]
        
        # ìš”ì¼ëª… ì¶”ê°€
        weekday_names = {0: 'ì›”', 1: 'í™”', 2: 'ìˆ˜', 3: 'ëª©', 4: 'ê¸ˆ', 5: 'í† ', 6: 'ì¼'}
        weekday['weekday_name'] = weekday['weekday'].map(weekday_names)
        
        weekday.to_sql('agg_weekday', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(weekday)}ê°œ ìš”ì¼ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_monthly_aggregate(self, df):
        """ì›”ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„±"""
        print("\n[10/10] ì›”ë³„ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        monthly = df.groupby('month').agg({
            'revenue': 'sum',
            'units_sold': 'sum',
            'total_cost': 'sum',
            'real_profit': 'sum',
            'roi_calculated': 'mean',
            'broadcast': 'count'
        }).reset_index()
        
        monthly.columns = [
            'month', 'revenue_sum', 'units_sum', 'cost_sum',
            'profit_sum', 'roi_mean', 'broadcast_count'
        ]
        
        monthly.to_sql('agg_monthly', self.conn, if_exists='replace', index=False)
        print(f"  âœ“ {len(monthly)}ê°œ ì›”ë³„ ë ˆì½”ë“œ ì €ì¥")
    
    def _create_indexes(self):
        """ì¸ë±ìŠ¤ ìƒì„±ìœ¼ë¡œ ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ"""
        print("\nì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_agg_daily_date ON agg_daily(date)",
            "CREATE INDEX IF NOT EXISTS idx_agg_daily_weekday ON agg_daily(weekday)",
            "CREATE INDEX IF NOT EXISTS idx_agg_hourly_hour ON agg_hourly(hour)",
            "CREATE INDEX IF NOT EXISTS idx_agg_platform_name ON agg_platform(platform)",
            "CREATE INDEX IF NOT EXISTS idx_agg_platform_revenue ON agg_platform(revenue_sum DESC)",
            "CREATE INDEX IF NOT EXISTS idx_agg_category_name ON agg_category(category)",
            "CREATE INDEX IF NOT EXISTS idx_agg_platform_hourly ON agg_platform_hourly(platform, hour)",
            "CREATE INDEX IF NOT EXISTS idx_agg_category_hourly ON agg_category_hourly(category, hour)",
        ]
        
        for idx_query in indexes:
            self.cur.execute(idx_query)
        
        self.conn.commit()
        print("  âœ“ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    
    def _save_statistics(self, df):
        """í†µê³„ ì •ë³´ ì €ì¥"""
        print("\ní†µê³„ ì •ë³´ ì €ì¥ ì¤‘...")
        
        # ê¸°íƒ€ ì œì™¸ í†µê³„
        total_records = len(df)
        
        # ì›ë³¸ ë°ì´í„°ì—ì„œ ê¸°íƒ€ ë¹„ìœ¨ ê³„ì‚°
        self.cur.execute("SELECT COUNT(*) FROM schedule WHERE platform = 'ê¸°íƒ€'")
        others_count = self.cur.fetchone()[0]
        
        self.cur.execute("SELECT COUNT(*) FROM schedule")
        total_original = self.cur.fetchone()[0]
        
        stats = {
            'created_at': datetime.now().isoformat(),
            'total_records': total_records,
            'others_excluded': others_count,
            'others_ratio': (others_count / total_original * 100) if total_original > 0 else 0,
            'date_range': f"{df['date'].min().date()} ~ {df['date'].max().date()}",
            'platforms': len(df['platform'].unique()),
            'categories': len(df['category'].unique()),
            'total_revenue': int(df['revenue'].sum()),
            'total_profit': int(df['real_profit'].sum()),
            'avg_roi': float(df['roi_calculated'].mean()),
            'real_margin_rate': REAL_MARGIN_RATE,  # ìƒˆë¡œìš´ ë§ˆì§„ìœ¨ ì €ì¥
            'conversion_rate': CONVERSION_RATE,     # ì „í™˜ìœ¨ ì €ì¥
            'product_cost_rate': PRODUCT_COST_RATE, # ì œí’ˆ ì›ê°€ìœ¨ ì €ì¥
            'commission_rate': COMMISSION_RATE      # íŒë§¤ ìˆ˜ìˆ˜ë£Œìœ¨ ì €ì¥
        }
        
        # í†µê³„ í…Œì´ë¸” ìƒì„±
        stats_df = pd.DataFrame([stats])
        stats_df.to_sql('agg_statistics', self.conn, if_exists='replace', index=False)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ì§‘ê³„ í†µê³„")
        print("=" * 60)
        print(f"ìƒì„± ì‹œê°: {stats['created_at']}")
        print(f"ì²˜ë¦¬ ë ˆì½”ë“œ: {stats['total_records']:,}ê°œ")
        print(f"ì œì™¸ëœ 'ê¸°íƒ€': {stats['others_excluded']:,}ê°œ ({stats['others_ratio']:.1f}%)")
        print(f"ê¸°ê°„: {stats['date_range']}")
        print(f"ë°©ì†¡ì‚¬: {stats['platforms']}ê°œ")
        print(f"ì¹´í…Œê³ ë¦¬: {stats['categories']}ê°œ")
        print(f"ì´ ë§¤ì¶œ: {stats['total_revenue']:,}ì›")
        print(f"í‰ê·  ROI: {stats['avg_roi']:.2f}%")
        print(f"ì ìš©ëœ ì‹¤ì§ˆ ë§ˆì§„ìœ¨: {stats['real_margin_rate']:.2%}")

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def check_aggregate_tables(db_path="schedule.db"):
    """ì§‘ê³„ í…Œì´ë¸” ìƒíƒœ í™•ì¸"""
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()
    
    print("\n" + "=" * 60)
    print("ì§‘ê³„ í…Œì´ë¸” ìƒíƒœ í™•ì¸")
    print("=" * 60)
    
    # í…Œì´ë¸” ëª©ë¡
    tables = [
        'agg_daily', 'agg_hourly', 'agg_platform', 'agg_category',
        'agg_platform_hourly', 'agg_category_hourly', 'agg_weekday',
        'agg_monthly', 'agg_statistics'
    ]
    
    for table in tables:
        cur.execute(f"SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name='{table}'")
        exists = cur.fetchone()[0] > 0
        
        if exists:
            cur.execute(f"SELECT COUNT(*) FROM {table}")
            count = cur.fetchone()[0]
            print(f"âœ… {table:20} : {count:8,} rows")
        else:
            print(f"âŒ {table:20} : ì—†ìŒ")
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    try:
        stats_df = pd.read_sql_query("SELECT * FROM agg_statistics", conn)
        if len(stats_df) > 0:
            stats = stats_df.iloc[0]
            print("\nğŸ“Š ë§ˆì§€ë§‰ ì§‘ê³„ ì •ë³´:")
            print(f"  - ìƒì„± ì‹œê°: {stats['created_at']}")
            print(f"  - ì œì™¸ëœ 'ê¸°íƒ€': {stats['others_excluded']:,}ê°œ")
            print(f"  - ê¸°ê°„: {stats['date_range']}")
            if 'real_margin_rate' in stats:
                print(f"  - ì‹¤ì§ˆ ë§ˆì§„ìœ¨: {stats['real_margin_rate']:.2%}")
            if 'conversion_rate' in stats:
                print(f"  - ì „í™˜ìœ¨: {stats['conversion_rate']:.0%}")
    except:
        pass
    
    conn.close()

def drop_aggregate_tables(db_path="schedule.db"):
    """ëª¨ë“  ì§‘ê³„ í…Œì´ë¸” ì‚­ì œ"""
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()
    
    tables = [
        'agg_daily', 'agg_hourly', 'agg_platform', 'agg_category',
        'agg_platform_hourly', 'agg_category_hourly', 'agg_weekday',
        'agg_monthly', 'agg_statistics'
    ]
    
    print("\nì§‘ê³„ í…Œì´ë¸” ì‚­ì œ ì¤‘...")
    for table in tables:
        cur.execute(f"DROP TABLE IF EXISTS {table}")
        print(f"  - {table} ì‚­ì œ")
    
    conn.commit()
    conn.close()
    print("âœ… ëª¨ë“  ì§‘ê³„ í…Œì´ë¸” ì‚­ì œ ì™„ë£Œ")

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ëŒ€ì‹œë³´ë“œ ì§‘ê³„ í…Œì´ë¸” ìƒì„±")
    parser.add_argument("--db", default="schedule.db", help="ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ")
    parser.add_argument("--include-others", action="store_true", 
                       help="'ê¸°íƒ€' ë°ì´í„°ë„ í¬í•¨ (ê¸°ë³¸: ì œì™¸)")
    parser.add_argument("--check", action="store_true", 
                       help="ì§‘ê³„ í…Œì´ë¸” ìƒíƒœ í™•ì¸")
    parser.add_argument("--drop", action="store_true", 
                       help="ëª¨ë“  ì§‘ê³„ í…Œì´ë¸” ì‚­ì œ")
    
    args = parser.parse_args()
    
    if args.check:
        check_aggregate_tables(args.db)
    elif args.drop:
        drop_aggregate_tables(args.db)
    else:
        # ì§‘ê³„ í…Œì´ë¸” ìƒì„±
        creator = AggregateTableCreator(args.db)
        creator.create_all_tables(exclude_others=not args.include_others)
        
        # ìƒíƒœ í™•ì¸
        check_aggregate_tables(args.db)
        
        print("\n" + "=" * 60)
        print("âœ¨ ì§‘ê³„ í…Œì´ë¸” ìƒì„± ì™„ë£Œ!")
        print("ëŒ€ì‹œë³´ë“œì—ì„œ ì§‘ê³„ í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ 10ë°° ì´ìƒ í–¥ìƒë©ë‹ˆë‹¤.")
        print("=" * 60)